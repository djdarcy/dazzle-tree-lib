name: Tests

on:
  push:
    branches: [ main, dev, private ]
  pull_request:
    branches: [ main, dev ]
  workflow_dispatch:  # Allow manual trigger

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ['3.8', '3.9', '3.10', '3.11', '3.12']
        exclude:
          # Exclude some combinations to save CI minutes if needed
          - os: macos-latest
            python-version: '3.8'
          - os: macos-latest
            python-version: '3.9'

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .[dev]

    - name: Run fast tests
      run: |
        python run_tests.py --fast
      env:
        PYTHONPATH: ${{ github.workspace }}

    - name: Run full test suite (main branch only)
      if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
      run: |
        python run_tests.py
      env:
        PYTHONPATH: ${{ github.workspace }}

    - name: Upload test results
      if: failure()
      uses: actions/upload-artifact@v3
      with:
        name: test-results-${{ matrix.os }}-${{ matrix.python-version }}
        path: |
          test_runs/
          *.log

  lint:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .[dev]
        pip install flake8 black mypy

    - name: Check code formatting with black
      run: |
        black --check dazzletreelib tests
      continue-on-error: true  # Don't fail build on formatting issues

    - name: Lint with flake8
      run: |
        # Stop the build if there are Python syntax errors or undefined names
        flake8 dazzletreelib tests --count --select=E9,F63,F7,F82 --show-source --statistics
        # Exit-zero treats all errors as warnings
        flake8 dazzletreelib tests --count --exit-zero --max-complexity=10 --max-line-length=100 --statistics
      continue-on-error: true

    - name: Type checking with mypy
      run: |
        mypy dazzletreelib --ignore-missing-imports
      continue-on-error: true

  coverage:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .[dev]
        pip install pytest-cov

    - name: Run tests with coverage
      run: |
        pytest --cov=dazzletreelib --cov-report=xml --cov-report=html --cov-report=term
      continue-on-error: true

    - name: Upload coverage reports
      uses: actions/upload-artifact@v3
      with:
        name: coverage-report
        path: htmlcov/

    - name: Upload coverage to Codecov (optional)
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
      continue-on-error: true  # Don't fail if codecov is down

  benchmarks:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    # Performance tests are informational only - GitHub Actions runners have variable performance
    continue-on-error: true

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .[dev]

    - name: Run benchmarks (informational only)
      run: |
        echo "⚠️ NOTE: Performance results on GitHub Actions are not reliable due to shared infrastructure"
        echo "These results are for informational purposes only"
        echo "Run benchmarks locally for accurate measurements"
        echo ""
        python benchmarks/accurate_performance_test.py || echo "Benchmark completed with warnings"
      continue-on-error: true

    - name: Store benchmark results
      uses: actions/upload-artifact@v3
      if: always()  # Store results even if benchmarks fail
      with:
        name: benchmark-results-informational
        path: |
          benchmarks/*.txt
          benchmarks/*.log